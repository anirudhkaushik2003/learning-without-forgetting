{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576877c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c36294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a pretrained model (imageNet)\n",
    "data_dir = \"./data/hymenoptera_data\"\n",
    "model_name = \"resnet\" #choosing alexnet since it is \"relatively\" easy to train\n",
    "# model_name = \"squeezenet\" # changed to squeezeNet since it gets same acc as alex but smaller\n",
    "num_classes = 100 # in cifar100\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "feature_extract = False #set to false so we can finetune entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7c86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "stats = ((0.5074,0.4867,0.4411),(0.2011,0.1987,0.2025))\n",
    "train_transform = tt.Compose([\n",
    "    tt.RandomHorizontalFlip(),\n",
    "    tt.RandomCrop(32,padding=4,padding_mode=\"reflect\"),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(*stats)\n",
    "])\n",
    "\n",
    "test_transform = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(*stats)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f91442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_data = CIFAR100(download=True,root=\"./data\",transform=train_transform)\n",
    "test_data = CIFAR100(root=\"./data\",train=False,transform=test_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "166ca9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_classes = [1,2,17]\n",
    "sub_classes = [5,6,9,10,11,12,85,86,87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd1cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:21<00:00, 2369.09it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 7545.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "train_2 = []\n",
    "test_2 = []\n",
    "for i in tqdm(train_data):\n",
    "    if i[1] in sub_classes:\n",
    "        train_2.append(i)\n",
    "    \n",
    "for i in tqdm(test_data):\n",
    "    if i[1] in sub_classes:\n",
    "        test_2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad560ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR9_train(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        train_x = list(zip(*train_2))[0]\n",
    "        train_y = list(zip(*train_2))[1]\n",
    "        \n",
    "        train_y = np.array(train_y)\n",
    "        \n",
    "        self.x = torch.cat(train_x)\n",
    "        self.y = torch.from_numpy(train_y)  \n",
    "        \n",
    "        \n",
    "        self.n_samples = train_y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "        \n",
    "class CIFAR9_test(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        test_x = list(zip(*test_2))[0]\n",
    "        test_y = list(zip(*test_2))[1]\n",
    "        \n",
    "        test_y = np.array(test_y)\n",
    "        \n",
    "        self.x = torch.cat(test_x)\n",
    "        self.y = torch.from_numpy(test_y)    \n",
    "        \n",
    "        self.n_samples = test_y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7dda1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "trainData = CIFAR9_train()\n",
    "testData = CIFAR9_test()\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testData, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
