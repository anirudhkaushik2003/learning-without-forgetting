{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576877c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import operator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c36294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a pretrained model (imageNet)\n",
    "data_dir = \"./data/hymenoptera_data\"\n",
    "model_name = \"resnet\" #choosing alexnet since it is \"relatively\" easy to train\n",
    "# model_name = \"squeezenet\" # changed to squeezeNet since it gets same acc as alex but smaller\n",
    "num_classes = 100 # in cifar100\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "feature_extract = False #set to false so we can finetune entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7c86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "stats = ((0.5074,0.4867,0.4411),(0.2011,0.1987,0.2025))\n",
    "train_transform = tt.Compose([\n",
    "    tt.RandomHorizontalFlip(),\n",
    "    tt.RandomCrop(32,padding=4,padding_mode=\"reflect\"),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(*stats)\n",
    "])\n",
    "\n",
    "test_transform = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(*stats)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f91442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_data = CIFAR100(download=True,root=\"./data\",transform=train_transform)\n",
    "test_data = CIFAR100(root=\"./data\",train=False,transform=test_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "166ca9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_classes = [1,2,17]\n",
    "sub_classes = [5,6,9,10,11,12,85,86,87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd1cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [05:44<00:00, 145.12it/s]\n",
      "100%|██████████| 10000/10000 [00:27<00:00, 364.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "train_2 = []\n",
    "test_2 = []\n",
    "for i in tqdm(train_data):\n",
    "    if i[1] in sub_classes:\n",
    "        train_2.append(i)\n",
    "    \n",
    "for i in tqdm(test_data):\n",
    "    if i[1] in sub_classes:\n",
    "        test_2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad560ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR9_train(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        train_x = list(zip(*train_2))[0]\n",
    "        train_y = list(zip(*train_2))[1]\n",
    "        \n",
    "        train_y = np.array(train_y)\n",
    "        \n",
    "        self.x = torch.stack(train_x)\n",
    "        \n",
    "        self.y = torch.from_numpy(train_y)  \n",
    "        \n",
    "        \n",
    "        self.n_samples = train_y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "        \n",
    "class CIFAR9_test(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        test_x = list(zip(*test_2))[0]\n",
    "        test_y = list(zip(*test_2))[1]\n",
    "        \n",
    "        test_y = np.array(test_y)\n",
    "        \n",
    "        self.x = torch.stack(test_x)\n",
    "        self.y = torch.from_numpy(test_y)    \n",
    "        \n",
    "        self.n_samples = test_y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7dda1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainData = CIFAR9_train()\n",
    "testData = CIFAR9_test()\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testData, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d62fdb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 534/50000 [00:03<05:26, 151.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5b6365dfc78e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_cifar10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_cifar10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_classes_10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_cifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tobytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2533\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "super_classes_10 = [1,2,15,17] #15-> reptiles\n",
    "sub_classes_10 = [5,6,9,10,11,12,75,85,86,87,] # 75-> crocodile\n",
    "from tqdm import tqdm\n",
    "train_cifar10 = []\n",
    "test_cifar10 = []\n",
    "for i in tqdm(train_data):\n",
    "    if i[1] in sub_classes_10:\n",
    "        train_cifar10.append(i)\n",
    "    \n",
    "for i in tqdm(test_data):\n",
    "    if i[1] in sub_classes_10:\n",
    "        test_cifar10.append(i)\n",
    "        \n",
    "class CIFAR10_train(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        train_x = list(zip(*train_cifar10))[0]\n",
    "        train_y = list(zip(*train_cifar10))[1]\n",
    "        \n",
    "        train_y = np.array(train_y)\n",
    "        \n",
    "        self.x = torch.stack(train_x)\n",
    "        self.y = torch.from_numpy(train_y)  \n",
    "        \n",
    "        \n",
    "        self.n_samples = train_y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "        \n",
    "class CIFAR10_test(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        test_x = list(zip(*test_cifar10))[0]\n",
    "        test_y = list(zip(*test_cifar10))[1]\n",
    "        \n",
    "        test_y = np.array(test_y)\n",
    "        \n",
    "        self.x = torch.stack(test_x)\n",
    "        self.y = torch.from_numpy(test_y)    \n",
    "        \n",
    "        self.n_samples = test_y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f2143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
