{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f4b1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.13.0\n",
      "Torchvision Version:  0.14.0\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import numpy as np\n",
    "from iirc.datasets_loader import get_lifelong_datasets\n",
    "from iirc.definitions import PYTORCH, IIRC_SETUP\n",
    "from iirc.utils.download_cifar import download_extract_cifar100\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.transforms as tt\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import MultilabelJaccardIndex\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"Torchvision Version: \", torchvision.__version__)\n",
    "\n",
    "from IIRC_CIFAR_HIERARCHY import classHierarchy\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2194ea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting CIFAR 100\n",
      "dataset extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/anirudhkaushik/miniconda3/envs/pytorch/lib/python3.10/site-packages/iirc/utils/download_cifar.py:15: UserWarning: ../../data/cifar-100-python.tar.gz already exists, the dataset won't be download\n",
      "  warnings.warn(f\"{target_path} already exists, the dataset won't be download\")\n"
     ]
    }
   ],
   "source": [
    "download_extract_cifar100(\"../../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ae20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "essential_transforms_fn = transforms.ToTensor()\n",
    "augmentation_transforms_fn = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42eb54d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating iirc_cifar100\n",
      "Setup used: IIRC\n",
      "Using PyTorch\n",
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "dataset_splits, tasks, class_names_to_idx = \\\n",
    "    get_lifelong_datasets(dataset_name = \"iirc_cifar100\",\n",
    "                          dataset_root = \"../../data\", # the imagenet folder (where the train and val folders reside, or the parent directory of cifar-100-python folder\n",
    "                          setup = IIRC_SETUP,\n",
    "                          framework = PYTORCH,\n",
    "                          tasks_configuration_id = 0,\n",
    "                          essential_transforms_fn = essential_transforms_fn,\n",
    "                          augmentation_transforms_fn = augmentation_transforms_fn,\n",
    "                          joint = True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91edc066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(tasks))\n",
    "n_classes_per_task = []\n",
    "for task in tasks:\n",
    "    n_classes_per_task.append(len(task))\n",
    "n_classes_per_task = np.array(n_classes_per_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d580e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "intask_valid\n",
      "posttask_valid\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "# lifelong_datasets['train'].choose_task(2)\n",
    "# print(list(zip(*lifelong_datasets['train']))[1])\n",
    "for i in dataset_splits:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b4d9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a pretrained model (imageNet)\n",
    "model_name = \"resnet\" #choosing alexnet since it is \"relatively\" easy to train\n",
    "# model_name = \"squeezenet\" # changed to squeezeNet since it gets same acc as alex but smaller\n",
    "num_classes = 9 # in cifar100\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "num_epochs = 14\n",
    "\n",
    "feature_extract = False #set to false so we can finetune entire model\n",
    "\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2156c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, testloader, criterion, optimizer, num_classes, num_epochs=5 ):\n",
    "    since = time.time() # including this just because\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        \n",
    "                \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # iterate over data\n",
    "        for inputs,label1,label2 in tqdm(trainloader):\n",
    "            inputs = inputs.to(device)\n",
    "            label1 = torch.from_numpy(np.array([class_names_to_idx[i] for i in label1]))\n",
    "            label1 = F.one_hot(label1, num_classes=num_classes)\n",
    "            label1 = label1.to(torch.float32)\n",
    "            label1 = label1.to(device)\n",
    "#             label2 = label2.to(device)\n",
    "\n",
    "\n",
    "            #empty the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "#             print(label1.dtype, outputs.dtype)\n",
    "#             print(outputs,label1)\n",
    "            loss = criterion(outputs, label1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "#             running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "        epoch_loss = running_loss / len(trainloader.dataset)\n",
    "        print(\"len dataset = \",len(trainloader.dataset))\n",
    "#             epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "        print('{} Loss: {:.4f}'.format('train', epoch_loss))\n",
    "\n",
    "        print()\n",
    "        test_model(model, testloader, num_classes, mode=0)\n",
    "        model = model.to(device)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59383894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3e9559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, num_layers=18):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        if num_layers not in [18, 34, 50, 101, 152]:\n",
    "            raise ValueError(\"For ResNet, choose a number of layers out of 18, 34, 50, 101, and 152\")\n",
    "        elif num_layers == 18:\n",
    "            self.model = models.resnet18()\n",
    "        elif num_layers == 34:\n",
    "            self.model = models.resnet34()\n",
    "        elif num_layers == 50:\n",
    "            self.model = models.resnet50()\n",
    "        elif num_layers == 101:\n",
    "            self.model = models.resnet101()\n",
    "        elif num_layers == 152:\n",
    "            self.model = models.resnet152()\n",
    "\n",
    "        latent_dim = self.model.fc.in_features\n",
    "        self.model.fc = nn.Identity()  # replace the builtin fully connected layer with an identity layer\n",
    "        self.model.output_layer = nn.Linear(latent_dim, self.num_classes)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        x = self.model(input_)\n",
    "        output = self.model.output_layer(x)\n",
    "        return output, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52188c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes):\n",
    "    model_ft = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a54114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,testloader,num_classes,mode=0):\n",
    "    correct = 0\n",
    "    total = len(testloader.dataset)\n",
    "    running_corrects = 0 \n",
    "    JS = MultilabelJaccardIndex(num_labels = int(num_classes), average='weighted')\n",
    "    with torch.no_grad():\n",
    "        print(f\"Begining Testing on {num_classes} classes\")\n",
    "        for i,data in enumerate(tqdm(testloader)):\n",
    "            images, label1,label2 = data\n",
    "            images = images.to(device)\n",
    "            # since subclass labels are introduced after their corresponding superclass labels,\n",
    "            # in case we encounter a subclass label, we can assume it's superclass label has already been introduced\n",
    "            # or that it's superclass does not exist\n",
    "            if not any([class_names_to_idx[j] for j in label1] < seen_classes):\n",
    "                continue\n",
    "            og_label = (0,0)    \n",
    "            if label1 in classHierarchy or label1 in classHierarchy.values(): #if subclass has superclass or is superclass\n",
    "                if label1 in classHierarchy.values(): # if label is superclass label\n",
    "                    label1 = torch.from_numpy(np.array([class_names_to_idx[i] for i in label1]))\n",
    "                    \n",
    "                    og_label = label1\n",
    "                    label1 = F.one_hot(label1, num_classes=num_classes)\n",
    "                    \n",
    "                    label1 = label1.to(torch.int32)\n",
    "\n",
    "                    label = label1\n",
    "                else: # if label is subclass and has superclass\n",
    "                    label2 = label1\n",
    "                    label1 = classHierarchy[label1]\n",
    "                    \n",
    "                    label1 = torch.from_numpy(np.array([class_names_to_idx[i] for i in label1]))\n",
    "                    \n",
    "                    label1 = F.one_hot(label1, num_classes=num_classes)\n",
    "                    label1 = label1.to(torch.int32)\n",
    "\n",
    "                    label2 = torch.from_numpy(np.array([class_names_to_idx[i] for i in label2]))\n",
    "                    og_label = label2\n",
    "                    label2 = F.one_hot(label2, num_classes=num_classes)\n",
    "                    label2 = label2.to(torch.int32)\n",
    "\n",
    "                    label = label1 + label2\n",
    "                    \n",
    "            else: # subclass has no superclass\n",
    "                label1 = torch.from_numpy(np.array([class_names_to_idx[i] for i in label1]))\n",
    "                og_label = label1\n",
    "                label1 = F.one_hot(label1, num_classes=num_classes)\n",
    "                label1 = label1.to(torch.int32)\n",
    "\n",
    "                label = label1\n",
    "\n",
    "#             label = label.to(torch.int32)\n",
    "            outputs = model(images).detach().cpu() # sigmoidless activation\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "#             print(predicted)\n",
    "\n",
    "            correct += JS(outputs,label)\n",
    "            running_corrects += torch.sum(preds == og_label.data)\n",
    "#             correct += (predicted == label).sum().item()\n",
    "#             correct /= batch_size\n",
    "\n",
    "#             print(preds,label)\n",
    "        if mode == 0:\n",
    "            print(f\"In-task validation JS: {correct / total} \")\n",
    "            print(f\"In-task validation accuracy: {running_corrects / total} \")\n",
    "            \n",
    "        elif mode == 1:\n",
    "            print(f\"Post-task validation JS: {correct / total} \")\n",
    "            print(f\"Post-task validation accuracy: {running_corrects / total} \")\n",
    "            \n",
    "        elif mode == 2:\n",
    "            print(f\"Final Test JS: {correct /total} \")\n",
    "            print(f\"Final Test accuracy: {running_corrects / total} \")\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3f18d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'num_ftrs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 34\u001b[0m\n\u001b[1;32m     29\u001b[0m PostTask_valloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(posttask_val_data, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     31\u001b[0m seen_classes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m n_classes_per_task[task]\n\u001b[0;32m---> 34\u001b[0m new_fc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[43mresnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_ftrs\u001b[49m, seen_classes)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seen_classes\u001b[38;5;241m-\u001b[39mn_classes_per_task[task]):\n\u001b[1;32m     37\u001b[0m     new_fc\u001b[38;5;241m.\u001b[39mweight[cl]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m resnet\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mweight[cl]\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1265\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'num_ftrs'"
     ]
    }
   ],
   "source": [
    "# Setup \n",
    "# BCE loss for multi-label classification\n",
    "# sigmoid activation after FC layer \n",
    "# everything above 0.5 is a predicted label\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # as output is sigmoidless\n",
    "\n",
    "# get dataset corresponding to each split\n",
    "train_data = dataset_splits[\"train\"]\n",
    "intask_val_data = dataset_splits[\"intask_valid\"]\n",
    "posttask_val_data = dataset_splits[\"posttask_valid\"]\n",
    "test_data = dataset_splits[\"test\"]\n",
    "\n",
    "# pre-trained Model on imageNet \n",
    "# resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "seen_classes = 0\n",
    "resnet = ResNet(num_classes=10, num_layers=18 )\n",
    "# resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "\n",
    "# initialize data to train on first task\n",
    "for task in range(len(tasks)):\n",
    "    train_data.choose_task(task)\n",
    "    intask_val_data.choose_task(task)\n",
    "    posttask_val_data.choose_task(task)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    InTask_valloader = torch.utils.data.DataLoader(intask_val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    PostTask_valloader = torch.utils.data.DataLoader(posttask_val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    seen_classes += n_classes_per_task[task]\n",
    "    \n",
    "        \n",
    "    new_fc = nn.Linear(resnet.num_ftrs, seen_classes)\n",
    "    \n",
    "    for cl in range(seen_classes-n_classes_per_task[task]):\n",
    "        new_fc.weight[cl].data = resnet.fc.weight[cl].data\n",
    "            \n",
    "    resnet.fc = new_fc\n",
    "    resnet = resnet.to(device)\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        print(f\"Training on multiple gps ({ngpu})\")    \n",
    "        resnet = nn.DataParallel(resnet,list(range(ngpu)))\n",
    "    params_to_update = resnet.parameters()\n",
    "\n",
    "    optimizer_ft = optim.SGD(params_to_update, lr=1.0, momentum=0.9)\n",
    "    \n",
    "    print(f\"Begining Training on Task {task+1}\")\n",
    "    resnet = train_model(resnet, trainloader, InTask_valloader, criterion, optimizer_ft , seen_classes,num_epochs)\n",
    "    test_model(resnet, InTask_valloader,seen_classes, mode=1)\n",
    "\n",
    "# resnet = train_model(resnet, dataloader_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b07933",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"models/resnet50_JOINT.pth\"\n",
    "torch.save(resnet.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0905a0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
